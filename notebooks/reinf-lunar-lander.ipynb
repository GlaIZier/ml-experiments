{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767687b5-10fd-435a-97e1-82cb0d9f97ed",
   "metadata": {},
   "source": [
    "8. Reinf learning. Exercise: Use policy gradients to solve OpenAI Gym's LunarLander-v2 environment. You will need to install the Box2D dependencies (%pip install -U gym[box2d]). hands-on-ml book exerices page 623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbee982d-cf3a-4dfb-bddf-4fbc605513f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0057251 ,  1.4133191 , -0.57989806,  0.10661198,  0.00664065,\n",
       "        0.13135552,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0320204f-372a-4e58-8271-4fce3bdb0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Box(-inf, inf, (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# img = env.render(mode=\"rgb_array\")\n",
    "# env.close()\n",
    "# plt.imshow(img)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4543afbd-bb27-4e8a-a317-f8ced879c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-169.92407972827417 114.42740302485342 -635.8544079743916 35.9482687013184\n"
     ]
    }
   ],
   "source": [
    "# random policy\n",
    "# print(np.mean(total_rewards), np.std(total_rewards), np.min(total_rewards), np.max(total_rewards))\n",
    "# -179.8682271598708 113.57826569586982 -536.6091716341286 11.068357820341546\n",
    "\n",
    "total_rewards = []\n",
    "for i_episode in range(200):\n",
    "    rewards = 0\n",
    "    obs = env.reset()\n",
    "    for t in range(200):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(rewards)\n",
    "print(np.mean(total_rewards), np.std(total_rewards), np.min(total_rewards), np.max(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ab7d47-4308-492f-a705-2403c6f1ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/Users/mkhokhlush/github/ml-experiments/.venv/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1348724e-05  1.3984330e+00 -1.1662395e-03 -5.5498195e-01\n",
      "   1.9964325e-05  2.6422073e-04  0.0000000e+00  0.0000000e+00]]\n",
      "4\n",
      "[<tf.Variable 'dense/kernel:0' shape=(8, 32) dtype=float32, numpy=\n",
      "array([[ 0.2789963 ,  0.08988687,  0.16530448,  0.38207805,  0.2952683 ,\n",
      "         0.14580142, -0.1053811 , -0.21996194, -0.34633228,  0.04505762,\n",
      "         0.12492645,  0.31540477,  0.00900206, -0.22102772,  0.06412408,\n",
      "        -0.37218946,  0.34160674, -0.29698238,  0.2313891 ,  0.34169775,\n",
      "        -0.17452796, -0.06045508,  0.01905298, -0.30262643,  0.15100622,\n",
      "        -0.3670276 ,  0.03495792,  0.22835463,  0.2387076 ,  0.3702411 ,\n",
      "        -0.00675628,  0.24074471],\n",
      "       [ 0.35841024, -0.10961273, -0.05431673,  0.27615982,  0.38315243,\n",
      "        -0.18301392,  0.2678724 ,  0.08674726, -0.31620517, -0.2634016 ,\n",
      "        -0.11574939,  0.37154955,  0.01541594,  0.2937876 ,  0.20555085,\n",
      "         0.26670808,  0.12947124, -0.03203493,  0.1795047 ,  0.02346125,\n",
      "         0.19778848, -0.18093094, -0.05169162, -0.2341456 ,  0.33978683,\n",
      "         0.19310945, -0.13669673,  0.12922037, -0.34182197, -0.29966483,\n",
      "        -0.24976827,  0.3648724 ],\n",
      "       [ 0.09504023,  0.18199605,  0.21084678,  0.09879971, -0.09958377,\n",
      "         0.16306424,  0.14896792, -0.02766094, -0.16734868,  0.24818003,\n",
      "        -0.3789835 ,  0.33045465, -0.09159774, -0.01973841,  0.09263524,\n",
      "         0.3011611 , -0.1565559 , -0.36876985,  0.36396462, -0.10024557,\n",
      "        -0.2870211 ,  0.03657508, -0.36679444, -0.35412857, -0.31052113,\n",
      "        -0.20604126, -0.3021133 , -0.09037423, -0.05705774, -0.19164948,\n",
      "        -0.0041174 , -0.22269213],\n",
      "       [-0.00824091, -0.07445738, -0.1026378 ,  0.12250006,  0.21611714,\n",
      "         0.24492443,  0.02132654, -0.11280525, -0.34875053,  0.2777686 ,\n",
      "        -0.05988052,  0.14913201, -0.266269  ,  0.38274056, -0.18767631,\n",
      "         0.1601131 , -0.38144007,  0.22576934, -0.3414191 ,  0.10274446,\n",
      "        -0.180554  , -0.16285518, -0.13966338,  0.08932137,  0.12349987,\n",
      "         0.21968472, -0.17660338,  0.31566948, -0.02041212,  0.21731818,\n",
      "         0.3518985 , -0.06905878],\n",
      "       [ 0.32093877,  0.01253292,  0.01170141, -0.36419234,  0.06896752,\n",
      "        -0.02354842, -0.3508871 ,  0.15049797,  0.3037545 ,  0.09985736,\n",
      "        -0.27848703, -0.2955824 ,  0.3029182 , -0.30510867, -0.11857903,\n",
      "        -0.11087075, -0.3576934 , -0.29103082,  0.3215587 , -0.14884263,\n",
      "        -0.07908532, -0.3637779 ,  0.03981599, -0.24031423, -0.05202007,\n",
      "         0.05882788, -0.1802228 , -0.2746641 ,  0.34707373, -0.0027796 ,\n",
      "         0.00884959,  0.09036776],\n",
      "       [-0.29878622,  0.14334476,  0.00841495,  0.03926176,  0.02896723,\n",
      "         0.24091935, -0.1281415 , -0.36086822,  0.07830626, -0.02742648,\n",
      "        -0.28276685,  0.15317684,  0.24997622, -0.3659968 ,  0.21115768,\n",
      "        -0.17751624,  0.29342115,  0.08376017, -0.20169514, -0.05489442,\n",
      "         0.28078878,  0.13553369, -0.2064676 , -0.21579818,  0.10690784,\n",
      "        -0.03925732, -0.32222548,  0.1532548 , -0.21523206, -0.02933246,\n",
      "        -0.38153353,  0.18089908],\n",
      "       [ 0.27494454,  0.05270708,  0.22900563,  0.05979061, -0.11929828,\n",
      "         0.32692176,  0.08923432, -0.34990156,  0.01942438,  0.31954885,\n",
      "         0.2975989 , -0.16683233, -0.2065977 , -0.36799237,  0.17544878,\n",
      "         0.13385522,  0.36092567,  0.09398487,  0.07369566, -0.2699707 ,\n",
      "         0.11232489, -0.11431852,  0.25054735, -0.10856292,  0.24548781,\n",
      "        -0.23392823,  0.2153182 , -0.25395808,  0.03647625, -0.36165577,\n",
      "        -0.03561068, -0.22079466],\n",
      "       [-0.10083801, -0.12191191,  0.0640769 ,  0.10348889,  0.05803007,\n",
      "         0.21366256,  0.19588155,  0.29327774,  0.05487159, -0.14714378,\n",
      "         0.07821843,  0.1222595 , -0.21941826,  0.18259019, -0.2771325 ,\n",
      "         0.37186646, -0.24442054, -0.37781134, -0.15064998, -0.05636269,\n",
      "        -0.0123764 ,  0.08567548, -0.23495504,  0.06607133, -0.26260352,\n",
      "        -0.20704934, -0.2548495 ,  0.21867937, -0.30692166, -0.11083612,\n",
      "         0.07967564, -0.1431549 ]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(32, 12) dtype=float32, numpy=\n",
      "array([[-0.35378137,  0.2972003 , -0.02018845,  0.11470714,  0.08884597,\n",
      "         0.31324264,  0.23345867,  0.22069612, -0.32723403,  0.02201188,\n",
      "         0.02153647,  0.17850801],\n",
      "       [-0.04375118,  0.02321383, -0.04592451,  0.28727338,  0.19488266,\n",
      "         0.10969421, -0.2059888 ,  0.09003243,  0.15728447,  0.01331556,\n",
      "        -0.17614797, -0.35886025],\n",
      "       [ 0.06273425,  0.28905562, -0.01406619, -0.0980086 ,  0.2341424 ,\n",
      "         0.2313452 , -0.08143735, -0.23517838,  0.24687746, -0.19049238,\n",
      "        -0.10971454, -0.3045224 ],\n",
      "       [-0.19906141,  0.12042889, -0.00505501,  0.29416612, -0.19080845,\n",
      "        -0.19150609,  0.0987218 ,  0.11820242,  0.13092765, -0.05350527,\n",
      "         0.3031204 ,  0.10087276],\n",
      "       [ 0.28368315,  0.3058237 , -0.09230313,  0.15876076, -0.2066478 ,\n",
      "        -0.18164988, -0.21219549, -0.14762029, -0.23614834,  0.3173116 ,\n",
      "         0.28899726,  0.34362498],\n",
      "       [-0.1038647 , -0.32985088,  0.23763236, -0.3612881 , -0.0690555 ,\n",
      "         0.32672462, -0.20780845,  0.03615159,  0.07348248, -0.20584309,\n",
      "         0.2630138 , -0.02177021],\n",
      "       [-0.18157135, -0.3453425 , -0.02124611,  0.18077984,  0.20915028,\n",
      "        -0.17379972,  0.21426436, -0.29405525, -0.12783428,  0.174606  ,\n",
      "         0.02336043, -0.12909433],\n",
      "       [ 0.03175759, -0.2862712 ,  0.01355448, -0.23069441,  0.2583796 ,\n",
      "        -0.15022571, -0.03900132, -0.20706035, -0.35454258, -0.13243076,\n",
      "         0.33381262, -0.12212071],\n",
      "       [ 0.20406106,  0.07815364, -0.26323777, -0.3577078 ,  0.05960613,\n",
      "        -0.18436967, -0.35006645,  0.01599535,  0.15655515, -0.36195546,\n",
      "        -0.10269716,  0.09425369],\n",
      "       [ 0.22531632,  0.06414047,  0.19355497,  0.26713088, -0.0735752 ,\n",
      "        -0.09351879,  0.23164597,  0.06452495,  0.0940659 , -0.20845503,\n",
      "        -0.20683348,  0.09568024],\n",
      "       [-0.28664222,  0.12214923,  0.08391097, -0.17560977,  0.16212174,\n",
      "         0.28006515, -0.21836828, -0.2961895 , -0.28969103, -0.32067692,\n",
      "         0.2322804 ,  0.25301233],\n",
      "       [ 0.07267523,  0.1642504 , -0.1291947 ,  0.03111771, -0.08168411,\n",
      "        -0.24117862, -0.06765422,  0.28469315, -0.23033872, -0.04092029,\n",
      "         0.03998333, -0.30685207],\n",
      "       [ 0.11835277, -0.15329327,  0.3353074 , -0.15750237,  0.06029198,\n",
      "         0.27182803,  0.04038736,  0.07988289, -0.13934241, -0.2706067 ,\n",
      "         0.05766171,  0.29209265],\n",
      "       [-0.343788  , -0.1367362 , -0.33463377, -0.25515553,  0.29244366,\n",
      "        -0.17828175,  0.26743057, -0.16654497, -0.23568648,  0.13392463,\n",
      "         0.01031068,  0.1940758 ],\n",
      "       [ 0.21850112,  0.10193172, -0.36436057, -0.10732511,  0.1286225 ,\n",
      "        -0.14446609, -0.08682269,  0.2048271 , -0.17002167, -0.01924983,\n",
      "        -0.23749582, -0.21097311],\n",
      "       [ 0.25053164, -0.11457181,  0.12405235,  0.23877385,  0.17748824,\n",
      "        -0.11803442, -0.19106896,  0.2609789 , -0.06101462,  0.12031859,\n",
      "        -0.25062165, -0.21000315],\n",
      "       [-0.01899329, -0.20895563,  0.31795725,  0.14866796, -0.029026  ,\n",
      "        -0.18928382,  0.12209272,  0.18431595,  0.18060353,  0.34358206,\n",
      "         0.11546192,  0.22044244],\n",
      "       [ 0.30049607,  0.36820695,  0.12300527, -0.31620678,  0.18680605,\n",
      "         0.08477378, -0.05583563,  0.08643767,  0.3256109 , -0.08297586,\n",
      "        -0.3272636 , -0.23250015],\n",
      "       [-0.28611723,  0.22362968, -0.21231532,  0.19605514, -0.21778096,\n",
      "        -0.11012888, -0.0094322 ,  0.13706836, -0.33957592, -0.19722687,\n",
      "        -0.22054248, -0.00223583],\n",
      "       [-0.33081952,  0.14744183,  0.0206652 ,  0.36253187,  0.2672558 ,\n",
      "        -0.31209671,  0.25171295,  0.23626938,  0.3646094 ,  0.13042068,\n",
      "        -0.29779872, -0.17480154],\n",
      "       [ 0.312835  , -0.3612078 , -0.01712343,  0.10210228,  0.07694739,\n",
      "        -0.3150204 , -0.04360291,  0.02648413,  0.00346631,  0.21157303,\n",
      "        -0.08611456, -0.22548603],\n",
      "       [ 0.09821197,  0.10096857,  0.19365862, -0.20841558, -0.04426393,\n",
      "         0.3154483 , -0.1770651 ,  0.20641729,  0.14909014,  0.24694827,\n",
      "         0.14105031, -0.34686324],\n",
      "       [ 0.2861409 ,  0.28838596, -0.33812162, -0.3078302 , -0.18598129,\n",
      "         0.34945825, -0.06310764, -0.03096566, -0.16556305, -0.15700863,\n",
      "         0.3499566 ,  0.26628438],\n",
      "       [-0.18347244,  0.17668316,  0.35642025,  0.09090766, -0.29641628,\n",
      "        -0.00657427,  0.2047629 , -0.08890954,  0.23836103,  0.21203086,\n",
      "         0.29921547, -0.25677866],\n",
      "       [-0.22446026,  0.07412952,  0.2193034 ,  0.18572488, -0.3585148 ,\n",
      "        -0.16047211,  0.12399644, -0.14453512,  0.2534679 , -0.17966393,\n",
      "        -0.2860864 , -0.12190218],\n",
      "       [ 0.33444342, -0.32869244,  0.31036326, -0.15293695,  0.23828611,\n",
      "         0.29143366, -0.2910106 , -0.32608694, -0.01613551,  0.20871082,\n",
      "        -0.27289015,  0.28117207],\n",
      "       [ 0.21131465,  0.12455955,  0.0770267 ,  0.306842  ,  0.35853258,\n",
      "        -0.24631488, -0.00046229,  0.06670186, -0.01296893, -0.22492239,\n",
      "        -0.19013686, -0.12644692],\n",
      "       [-0.10925004, -0.36414206, -0.16865428, -0.05866426, -0.22420114,\n",
      "         0.33951637, -0.36839274, -0.2576031 ,  0.14452317,  0.14678803,\n",
      "         0.1462222 , -0.3481732 ],\n",
      "       [ 0.16151366, -0.01388949, -0.3064835 ,  0.31655428, -0.32804877,\n",
      "         0.03466272, -0.29020625,  0.05982825, -0.02143133,  0.07620758,\n",
      "        -0.3535177 , -0.26455593],\n",
      "       [-0.2614331 ,  0.04759932,  0.28395447, -0.35554442, -0.2585703 ,\n",
      "         0.16497687, -0.31699836,  0.22645608, -0.28201756, -0.33003393,\n",
      "        -0.13047297,  0.36307403],\n",
      "       [-0.04501891,  0.11241594, -0.09785125, -0.35323745,  0.30836037,\n",
      "         0.3500205 ,  0.03466174,  0.32061037,  0.10351104,  0.12026328,\n",
      "         0.02656955,  0.23406503],\n",
      "       [-0.33484226, -0.26725847,  0.3069004 ,  0.16326037,  0.23627487,\n",
      "        -0.11899638, -0.07572544, -0.2988695 ,  0.00926244, -0.08107647,\n",
      "         0.04179332, -0.08052769]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(12,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(12, 4) dtype=float32, numpy=\n",
      "array([[-2.25419670e-01,  5.73425114e-01,  4.16253209e-02,\n",
      "         6.46144748e-02],\n",
      "       [-3.01076919e-01,  6.11175358e-01,  5.95241129e-01,\n",
      "        -5.44100404e-02],\n",
      "       [-3.39709371e-01,  1.20266557e-01,  3.42293024e-01,\n",
      "        -2.13231653e-01],\n",
      "       [ 2.88164437e-01,  1.97680473e-01,  4.77195442e-01,\n",
      "        -3.30394506e-01],\n",
      "       [-2.88408995e-02, -3.91619861e-01,  3.86670887e-01,\n",
      "         5.72430193e-01],\n",
      "       [ 5.65219343e-01, -5.76643407e-01, -5.54057360e-01,\n",
      "         5.89635313e-01],\n",
      "       [ 3.36033642e-01, -1.08461380e-02, -3.59931588e-02,\n",
      "         5.92657745e-01],\n",
      "       [-3.12577575e-01,  3.37708294e-01, -2.27586895e-01,\n",
      "        -4.86876011e-01],\n",
      "       [ 5.40839732e-01, -1.17319375e-01,  2.57897556e-01,\n",
      "         3.63163710e-01],\n",
      "       [-2.51125753e-01,  5.92040598e-01,  1.09705329e-02,\n",
      "         4.99798715e-01],\n",
      "       [ 5.55658400e-01,  2.44042277e-02, -5.09161711e-01,\n",
      "        -3.04699063e-01],\n",
      "       [-1.12341762e-01,  1.55432642e-01,  4.53174114e-04,\n",
      "        -2.97970742e-01]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 16:53:08.502205: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(env.reset()[np.newaxis, :])\n",
    "print(env.action_space.n)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(env.observation_space.shape[0],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(12, activation='relu'))\n",
    "model.add(keras.layers.Dense(env.action_space.n, activation='softmax'))\n",
    "\n",
    "model(env.reset()[np.newaxis, :])\n",
    "print(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d27e72-a3bd-40dd-aa63-cee82b93dbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01114054,  1.420655  , -0.5589826 ,  0.20346141,  0.01134899,\n",
       "         0.09707952,  0.        ,  0.        ], dtype=float32),\n",
       " 0.7118944950623256,\n",
       " False,\n",
       " [<tf.Tensor: shape=(8, 32), dtype=float32, numpy=\n",
       "  array([[-4.2052063e-05,  0.0000000e+00,  0.0000000e+00, -1.3758638e-03,\n",
       "          -3.8100124e-04,  0.0000000e+00,  2.9844086e-04,  1.0833076e-03,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.8817047e-04,\n",
       "          -2.2810367e-04,  2.0687671e-03,  1.0566426e-03, -2.0732637e-04,\n",
       "          -3.8929511e-04,  1.0782813e-03,  0.0000000e+00, -1.8457569e-04,\n",
       "           2.3759750e-04,  0.0000000e+00,  5.9741607e-04,  0.0000000e+00,\n",
       "          -1.9600426e-03,  9.3876960e-04,  0.0000000e+00,  3.2559845e-05,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -3.7493880e-04],\n",
       "         [ 1.0634146e-02,  0.0000000e+00,  0.0000000e+00,  3.4792912e-01,\n",
       "           9.6347779e-02,  0.0000000e+00, -7.5469874e-02, -2.7394736e-01,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  4.7584642e-02,\n",
       "           5.7682969e-02, -5.2315086e-01, -2.6720431e-01,  5.2428797e-02,\n",
       "           9.8445132e-02, -2.7267629e-01,  0.0000000e+00,  4.6675593e-02,\n",
       "          -6.0083773e-02,  0.0000000e+00, -1.5107487e-01,  0.0000000e+00,\n",
       "           4.9565652e-01, -2.3739652e-01,  0.0000000e+00, -8.2337493e-03,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  9.4814710e-02],\n",
       "         [-4.2594788e-03,  0.0000000e+00,  0.0000000e+00, -1.3936208e-01,\n",
       "          -3.8591843e-02,  0.0000000e+00,  3.0229254e-02,  1.0972887e-01,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.9059900e-02,\n",
       "          -2.3104759e-02,  2.0954667e-01,  1.0702796e-01, -2.1000214e-02,\n",
       "          -3.9431933e-02,  1.0921976e-01,  0.0000000e+00, -1.8695783e-02,\n",
       "           2.4066392e-02,  0.0000000e+00,  6.0512632e-02,  0.0000000e+00,\n",
       "          -1.9853389e-01,  9.5088534e-02,  0.0000000e+00,  3.2980063e-03,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -3.7977777e-02],\n",
       "         [ 1.7207921e-03,  0.0000000e+00,  0.0000000e+00,  5.6301061e-02,\n",
       "           1.5590768e-02,  0.0000000e+00, -1.2212355e-02, -4.4329509e-02,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  7.7000330e-03,\n",
       "           9.3341209e-03, -8.4655024e-02, -4.3238364e-02,  8.4839026e-03,\n",
       "           1.5930157e-02, -4.4123828e-02,  0.0000000e+00,  7.5529329e-03,\n",
       "          -9.7226128e-03,  0.0000000e+00, -2.4446575e-02,  0.0000000e+00,\n",
       "           8.0205962e-02, -3.8414940e-02,  0.0000000e+00, -1.3323657e-03,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.5342690e-02],\n",
       "         [ 4.8778318e-05,  0.0000000e+00,  0.0000000e+00,  1.5959343e-03,\n",
       "           4.4194268e-04,  0.0000000e+00, -3.4617670e-04, -1.2565834e-03,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.1826847e-04,\n",
       "           2.6458903e-04, -2.3996681e-03, -1.2256533e-03,  2.4048839e-04,\n",
       "           4.5156313e-04, -1.2507532e-03,  0.0000000e+00,  2.1409871e-04,\n",
       "          -2.7560140e-04,  0.0000000e+00, -6.9297320e-04,  0.0000000e+00,\n",
       "           2.2735528e-03, -1.0889265e-03,  0.0000000e+00, -3.7767815e-05,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  4.3491053e-04],\n",
       "         [ 9.6483657e-04,  0.0000000e+00,  0.0000000e+00,  3.1567626e-02,\n",
       "           8.7416386e-03,  0.0000000e+00, -6.8473853e-03, -2.4855256e-02,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  4.3173567e-03,\n",
       "           5.2335788e-03, -4.7465503e-02, -2.4243459e-02,  4.7568674e-03,\n",
       "           8.9319320e-03, -2.4739934e-02,  0.0000000e+00,  4.2348788e-03,\n",
       "          -5.4514036e-03,  0.0000000e+00, -1.3707031e-02,  0.0000000e+00,\n",
       "           4.4970941e-02, -2.1538997e-02,  0.0000000e+00, -7.4704847e-04,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  8.6025428e-03],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "  array([ 0.00750959,  0.        , -0.        ,  0.24569942,  0.06803855,\n",
       "         -0.        , -0.05329506, -0.19345522, -0.        ,  0.        ,\n",
       "         -0.        ,  0.03360316,  0.04073437, -0.36943692, -0.18869343,\n",
       "          0.03702399,  0.06951965, -0.19255763,  0.        ,  0.03296121,\n",
       "         -0.04242976, -0.        , -0.10668554,  0.        ,  0.35002106,\n",
       "         -0.16764387,  0.        , -0.00581448,  0.        ,  0.        ,\n",
       "         -0.        ,  0.06695593], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 12), dtype=float32, numpy=\n",
       "  array([[ 0.        ,  0.        ,  0.09361478,  0.20761785, -0.1849523 ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.10835148,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.08225063,  0.18241456, -0.16250044,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.09519841,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.14727221,  0.32661873, -0.2909619 ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.17045559,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.06368784,  0.1412462 , -0.12582642,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.07371349,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.01549997,  0.03437568, -0.0306229 ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.01793996,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.08795985,  0.19507639, -0.17378   ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.10180636,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.01058681,  0.02347931, -0.02091608,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.01225337,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.10566685,  0.23434679, -0.20876324,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.12230077,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.05010757,  0.11112802, -0.09899623,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.05799543,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.05023811,  0.11141755, -0.09925414,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.05814653,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.04935439,  0.10945762, -0.09750818,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.05712368,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.05113566,  0.11340812, -0.10102741,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.05918536,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.02345448,  0.05201708, -0.0463384 ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.02714664,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.09908299,  0.21974519, -0.19575569,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.11468049,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.01729686,  0.03836079, -0.03417296,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.0200197 ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.15791422,  0.35022044, -0.31198704,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.18277285,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.09908507,  0.2197498 , -0.1957598 ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.1146829 ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.07310691,  0.16213572, -0.14443544,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.0846153 ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.14694639,  0.32589608, -0.29031816,\n",
       "           0.        ,  0.        ,  0.        ,  0.        , -0.17007846,\n",
       "           0.        ,  0.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
       "  array([ 0.        ,  0.        ,  0.22619116,  0.5016443 , -0.44688   ,\n",
       "         -0.        , -0.        ,  0.        , -0.        , -0.26179785,\n",
       "          0.        ,  0.        ], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(12, 4), dtype=float32, numpy=\n",
       "  array([[ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.03611151,  0.05135028,  0.050897  , -0.13835879],\n",
       "         [ 0.07545374,  0.10729462,  0.10634749, -0.28909582],\n",
       "         [ 0.02065222,  0.02936729,  0.02910806, -0.07912757],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.08080822,  0.11490866,  0.11389432, -0.3096112 ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.        ]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.20003948,  0.28445455,  0.2819436 , -0.7664376 ], dtype=float32)>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "# approach from the book\n",
    "# logits = tf.math.log(probas + keras.backend.epsilon())\n",
    "# action = tf.random.categorical(logits, num_samples=1)\n",
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        action_proba = model(obs[np.newaxis, :])[0]\n",
    "        rand = tf.random.uniform([env.action_space.n]) # choose random action according to actions' probability\n",
    "        actions = action_proba - rand\n",
    "        max_action_value = tf.reduce_max(actions)\n",
    "        action = int(tf.argmax(actions))\n",
    "        y_target = tf.cast(actions == max_action_value, tf.float32) # right action is equal to 1 (action above) and 0s (not action) \n",
    "        # print(action_proba, y_target)\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, action_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    return obs, reward, done, grads\n",
    "play_one_step(env, env.reset(), model, keras.losses.categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1ce77f-b611-4c02-ad5d-d80b6711d7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-22 -40 -50]\n",
      "[array([-0.28435071, -0.86597718, -1.18910299]), array([1.26665318, 1.0727777 ])]\n"
     ]
    }
   ],
   "source": [
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        obs = env.reset()\n",
    "        for step in range(n_max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads\n",
    "\n",
    "def discount_rewards(rewards, discount_factor=0.97):\n",
    "    discounted = np.array(rewards)\n",
    "    for n_reward in range(len(discounted) - 2, -1, -1):\n",
    "        discounted[n_reward] += discount_factor * discounted[n_reward + 1]\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_factor=0.97):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_factor) for rewards in all_rewards]\n",
    "    flat_all_discounted_rewards = np.concatenate(all_discounted_rewards)\n",
    "    flat_mean = np.mean(flat_all_discounted_rewards)\n",
    "    flat_std = np.std(flat_all_discounted_rewards)\n",
    "    return [(discounted_rewards - flat_mean) / flat_std for discounted_rewards in all_discounted_rewards]\n",
    "\n",
    "print(discount_rewards([10, 0, -50], 0.8)) # -22 -40 -50\n",
    "print(discount_and_normalize_rewards([[10, 0, -50], [10, 20]], 0.8)) # -0.28 .... 1.26, 1.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d6be02-f3f5-4a4c-ab89-9e917aea0c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [43:53<00:00,  8.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1671fcc70>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training algorithm: play several episodes without applying grads, then apply mean grad according to a reward\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "n_iterations = 300\n",
    "n_episodes_per_update = 12\n",
    "n_max_steps = 200\n",
    "discount_factor = 0.95\n",
    "\n",
    "optimizer = keras.optimizers.Adam(0.01)\n",
    "loss_fn = keras.losses.categorical_crossentropy\n",
    "\n",
    "def train():\n",
    "    iteration_rewards = []\n",
    "    final_iteration_rewards = []\n",
    "    for n_iteration in tqdm(range(n_iterations)):\n",
    "        all_rewards, all_grads = play_multiple_episodes(env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
    "        all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor)\n",
    "        # print(all_rewards)\n",
    "        # print(statistics.mean(all_rewards))\n",
    "        iteration_rewards.append(tf.reduce_mean(tf.ragged.constant(all_rewards)).numpy())\n",
    "        final_iteration_rewards.append(tf.reduce_mean(tf.ragged.constant(all_final_rewards)).numpy())\n",
    "        mean_grads = []\n",
    "        for trainable_var_index in range(len(model.trainable_variables)):\n",
    "            weighted_grads = []\n",
    "            for episode, final_rewards in enumerate(all_final_rewards):\n",
    "                for step, final_reward in enumerate(final_rewards):\n",
    "                    grad = all_grads[episode][step][trainable_var_index]\n",
    "                    weighted_grads.append(grad * final_reward) # the more reward the more grad is important\n",
    "            mean_grad = tf.reduce_mean(weighted_grads, axis=0) # reduce mean to get a mean grad between all episodes and steps\n",
    "            mean_grads.append(mean_grad)\n",
    "        optimizer.apply_gradients(zip(mean_grads, model.trainable_variables))  \n",
    "    return iteration_rewards, final_iteration_rewards\n",
    "iteration_rewards, final_iteration_rewards = train()\n",
    "\n",
    "plt.plot(iteration_rewards)\n",
    "plt.plot(final_iteration_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e647c2a5-f919-45a9-93c1-29a0a92f1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:49<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.460442828754037 22.81102173389233 -35.38405940311327 80.333859251291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# play with the trained model\n",
    "\n",
    "total_rewards = []\n",
    "for i_episode in tqdm(range(200)):\n",
    "    rewards = 0\n",
    "    obs = env.reset()\n",
    "    for t in range(200):\n",
    "        action_proba = model(obs[np.newaxis, :])[0]\n",
    "        action = int(tf.argmax(action_proba))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(rewards)\n",
    "# 29.660429310869976 24.329520575340702 -25.517524436082713 98.75970244131753\n",
    "print(np.mean(total_rewards), np.std(total_rewards), np.min(total_rewards), np.max(total_rewards))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccab51c2-3690-4fdc-b58c-6f8009e4bed7",
   "metadata": {},
   "source": [
    "# check the result\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def lander_render_policy_net(model, n_max_steps=500, seed=42):\n",
    "    frames = []\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    env.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    obs = env.reset()\n",
    "    for step in range(n_max_steps):\n",
    "        frames.append(env.render(mode=\"rgb_array\"))\n",
    "        probas = model(obs[np.newaxis])\n",
    "        logits = tf.math.log(probas + keras.backend.epsilon())\n",
    "        action = tf.random.categorical(logits, num_samples=1)\n",
    "        obs, reward, done, info = env.step(action[0, 0].numpy())\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return frames\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim\n",
    "\n",
    "frames = lander_render_policy_net(model, seed=42)\n",
    "plot_animation(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
