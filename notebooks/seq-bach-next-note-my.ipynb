{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe775a8-882e-4d5a-a72a-5fe5b3969cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66, 61, 57, 54], [66, 61, 57, 54], [68, 61, 59, 54], [68, 61, 59, 54], [69, 66, 61, 54], [69, 66, 61, 56], [69, 66, 61, 57], [69, 66, 61, 59], [68, 65, 61, 61], [68, 65, 61, 61], [68, 65, 59, 49], [68, 65, 59, 49], [66, 66, 57, 50], [66, 66, 57, 50], [66, 66, 57, 50], [66, 66, 57, 50], [66, 66, 59, 50], [66, 66, 59, 50], [68, 66, 59, 50], [68, 66, 59, 50], [69, 66, 61, 49], [69, 66, 61, 49], [69, 66, 61, 47], [69, 66, 61, 47], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 59, 49], [68, 65, 59, 49], [66, 61, 57, 42], [66, 61, 57, 42], [66, 61, 57, 42], [66, 61, 57, 42], [73, 66, 57, 54], [73, 66, 57, 54], [73, 66, 57, 54], [73, 66, 57, 54], [71, 66, 59, 56], [71, 66, 59, 56], [71, 65, 59, 56], [71, 65, 59, 56], [69, 66, 61, 57], [69, 66, 61, 57], [69, 66, 61, 59], [69, 66, 61, 59], [68, 65, 61, 61], [68, 65, 61, 61], [68, 65, 61, 61], [68, 65, 61, 61], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 61, 49], [69, 66, 61, 54], [69, 66, 61, 54], [69, 66, 61, 52], [69, 66, 61, 52], [69, 66, 62, 50], [69, 66, 62, 50], [69, 66, 62, 49], [69, 66, 62, 49], [71, 66, 62, 50], [71, 66, 62, 50], [71, 68, 64, 47], [71, 69, 66, 47], [71, 68, 64, 52], [71, 68, 64, 52], [71, 68, 62, 52], [71, 68, 62, 52], [73, 68, 61, 45], [73, 68, 61, 45], [73, 66, 61, 57], [73, 66, 61, 57], [73, 65, 59, 56], [73, 65, 59, 56], [73, 66, 57, 54], [73, 66, 57, 54], [71, 68, 62, 54], [71, 68, 62, 54], [71, 68, 61, 53], [71, 68, 61, 53], [69, 68, 61, 54], [69, 68, 61, 54], [69, 66, 62, 50], [69, 66, 62, 50], [68, 66, 62, 47], [68, 66, 62, 47], [68, 66, 59, 44], [68, 66, 59, 44], [68, 65, 56, 49], [68, 65, 56, 49], [68, 65, 59, 49], [68, 65, 59, 49], [66, 61, 57, 42], [66, 61, 57, 42], [66, 61, 57, 42], [66, 61, 57, 42], [73, 66, 57, 54], [73, 66, 57, 54], [73, 66, 57, 52], [73, 66, 57, 52], [71, 66, 59, 50], [71, 66, 59, 50], [71, 65, 61, 49], [71, 65, 61, 49], [69, 66, 63, 48], [69, 66, 63, 48], [68, 66, 63, 48], [68, 66, 63, 48], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 61, 49], [73, 66, 61, 45], [73, 66, 61, 45], [73, 64, 61, 45], [73, 64, 61, 45], [71, 63, 54, 47], [71, 63, 54, 47], [71, 64, 54, 49], [71, 64, 54, 49], [69, 66, 59, 51], [69, 66, 59, 51], [69, 63, 59, 47], [69, 63, 59, 47], [68, 64, 59, 52], [68, 64, 59, 52], [68, 64, 59, 52], [68, 64, 59, 52], [68, 68, 61, 53], [68, 68, 61, 53], [68, 65, 61, 49], [68, 65, 61, 49], [69, 66, 61, 54], [69, 66, 61, 54], [69, 66, 57, 54], [69, 66, 57, 54], [69, 69, 62, 54], [69, 69, 62, 54], [69, 66, 62, 50], [69, 66, 62, 50], [71, 62, 62, 56], [71, 62, 62, 56], [71, 62, 59, 56], [71, 62, 59, 56], [71, 71, 64, 56], [71, 71, 64, 56], [71, 68, 64, 52], [71, 68, 64, 52], [73, 69, 64, 57], [73, 69, 64, 57], [73, 67, 61, 57], [73, 67, 61, 57], [73, 66, 66, 58], [73, 66, 66, 58], [73, 66, 64, 54], [73, 66, 64, 54], [71, 66, 62, 59], [71, 66, 62, 59], [71, 65, 61, 59], [71, 65, 61, 59], [69, 66, 63, 60], [69, 66, 63, 60], [68, 66, 63, 56], [68, 66, 63, 56], [68, 66, 61, 61], [68, 66, 61, 61], [68, 65, 56, 61], [68, 63, 56, 61], [68, 65, 61, 49], [68, 65, 61, 49], [68, 65, 59, 49], [68, 65, 59, 49], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54], [66, 61, 57, 54]]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse \n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.data_folder = './data/bach-next-note/'\n",
    "args.train_folder = args.data_folder + 'train/'\n",
    "args.val_folder = args.data_folder + 'valid/'\n",
    "args.test_folder = args.data_folder + 'test/'\n",
    "# args.train_fraction = 0.8\n",
    "args.seed = 101\n",
    "args.batch_size = 32\n",
    "args.epochs = 50\n",
    "\n",
    "paths = Path(args.train_folder).glob('**/chorale_*.csv')\n",
    "train_np_list = [pd.read_csv(p).values.tolist() for p in paths]\n",
    "# print(len(train_np_list[0]))\n",
    "\n",
    "paths = Path(args.val_folder).glob('**/chorale_*.csv')\n",
    "val_np_list = [pd.read_csv(p).values.tolist() for p in paths]\n",
    "\n",
    "paths = Path(args.test_folder).glob('**/chorale_*.csv')\n",
    "test_np_list = [pd.read_csv(p).values.tolist() for p in paths]\n",
    "\n",
    "print(train_np_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acf44d-d366-4557-bfeb-b38904f7c425",
   "metadata": {},
   "source": [
    " ### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "465411bb-5f82-4054-92ea-37eaf0b497a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "128\n",
      "128\n",
      "Epoch 1/7\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 2/7\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 3/7\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 4/7\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 5/7\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 6/7\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 7/7\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5163.3491 - mean_squared_error: 5163.3491 - val_loss: 5196.8164 - val_mean_squared_error: 5196.8164\n",
      "Epoch 1/7\n",
      "8/8 [==============================] - 2s 73ms/step - loss: 4912.9937 - mean_squared_error: 4912.9937 - val_loss: 4914.8296 - val_mean_squared_error: 4914.8296\n",
      "Epoch 2/7\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 4880.6143 - mean_squared_error: 4880.6143 - val_loss: 4914.3530 - val_mean_squared_error: 4914.3530\n",
      "Epoch 3/7\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 4880.4062 - mean_squared_error: 4880.4062 - val_loss: 4914.2397 - val_mean_squared_error: 4914.2397\n",
      "Epoch 4/7\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 4880.3574 - mean_squared_error: 4880.3574 - val_loss: 4914.1963 - val_mean_squared_error: 4914.1963\n",
      "Epoch 5/7\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 4880.3389 - mean_squared_error: 4880.3389 - val_loss: 4914.1763 - val_mean_squared_error: 4914.1763\n",
      "Epoch 6/7\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 4880.3301 - mean_squared_error: 4880.3301 - val_loss: 4914.1655 - val_mean_squared_error: 4914.1655\n",
      "Epoch 7/7\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 4880.3247 - mean_squared_error: 4880.3247 - val_loss: 4914.1597 - val_mean_squared_error: 4914.1597\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15816d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 16:25:33,079 : WARNING : 5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15816d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "def baseline():\n",
    "    def build_dataset_baseline(chorales):\n",
    "        min_len = len(min(chorales, key=len))\n",
    "        print(min_len)\n",
    "\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def trunc(chorale):\n",
    "            return chorale[:min_len+1]\n",
    "\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        dataset = dataset.map(trunc)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "    #     for d in dataset:\n",
    "    #         tf.print(d)\n",
    "    #         break\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_baseline(train_np_list)\n",
    "    val_dataset = build_dataset_baseline(val_np_list)\n",
    "    test_dataset = build_dataset_baseline(test_np_list)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=[keras.metrics.mean_squared_error])\n",
    "    model.fit(train_dataset, epochs=args.epochs, validation_data=val_dataset)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "        keras.layers.SimpleRNN(1),\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=[keras.metrics.mean_squared_error])\n",
    "    model.fit(train_dataset, epochs=args.epochs, validation_data=val_dataset)\n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "    \n",
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e8137-84c9-4702-ab83-1950f4fce695",
   "metadata": {},
   "source": [
    "### Sparse categorical entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d0c12c34-4518-4a34-923b-a361b19f04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 81\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def min_max_notes(all_dataset_chorales=()):\n",
    "    min_note = None\n",
    "    max_note = None\n",
    "    def _min_max_notes():\n",
    "        nonlocal min_note\n",
    "        nonlocal max_note\n",
    "        if min_note:\n",
    "            return min_note, max_note\n",
    "        min_note = sys.maxsize\n",
    "        max_note = -sys.maxsize - 1\n",
    "        for chorales in all_dataset_chorales:\n",
    "            for ch in chorales:\n",
    "                ch = np.array(ch)\n",
    "                min_note = ch[ch > 0].min() if ch[ch > 0].min() < min_note else min_note\n",
    "                max_note = ch.max() if ch.max() > max_note else max_note\n",
    "            \n",
    "        return min_note, max_note\n",
    "\n",
    "    return _min_max_notes()\n",
    "\n",
    "\n",
    "def predict_next_notes(model, initial_seq_batch, length=25, model_return_seq=False):\n",
    "    for n_note in range(length):\n",
    "        note = np.argmax(model.predict(initial_seq_batch), axis=1)\n",
    "        if model_return_seq:\n",
    "            note = note[0]\n",
    "        initial_seq_batch = np.append(initial_seq_batch, note)\n",
    "        # get first\n",
    "    return initial_seq_batch\n",
    "\n",
    "\n",
    "\n",
    "min_note, max_note = min_max_notes((train_np_list, val_np_list, test_np_list))\n",
    "num_notes = (max_note - min_note + 1) + 1 # different notes + 0 (no note) note\n",
    "print(min_note, max_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f73c337-e91b-48a1-9c4a-b51fe003bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 47])\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 3s 56ms/step - loss: 3.2448 - accuracy: 0.1266 - val_loss: 2.8591 - val_accuracy: 0.1184\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.6639 - accuracy: 0.1659 - val_loss: 2.7154 - val_accuracy: 0.0921\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.5204 - accuracy: 0.1572 - val_loss: 2.6624 - val_accuracy: 0.0921\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.4773 - accuracy: 0.1572 - val_loss: 2.7170 - val_accuracy: 0.0526\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.4559 - accuracy: 0.1572 - val_loss: 2.6927 - val_accuracy: 0.0395\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.4374 - accuracy: 0.1616 - val_loss: 2.6426 - val_accuracy: 0.0789\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.4246 - accuracy: 0.1616 - val_loss: 2.6767 - val_accuracy: 0.0658\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.4090 - accuracy: 0.1790 - val_loss: 2.7314 - val_accuracy: 0.0526\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3971 - accuracy: 0.1790 - val_loss: 2.8415 - val_accuracy: 0.0263\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3891 - accuracy: 0.1747 - val_loss: 2.9143 - val_accuracy: 0.0263\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3831 - accuracy: 0.1921 - val_loss: 2.9340 - val_accuracy: 0.0395\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.3738 - accuracy: 0.1878 - val_loss: 2.8951 - val_accuracy: 0.0395\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3623 - accuracy: 0.2096 - val_loss: 2.7645 - val_accuracy: 0.0395\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3507 - accuracy: 0.2227 - val_loss: 2.6974 - val_accuracy: 0.0789\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3651 - accuracy: 0.2183 - val_loss: 3.1830 - val_accuracy: 0.0789\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3798 - accuracy: 0.1965 - val_loss: 2.9188 - val_accuracy: 0.1316\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.3300 - accuracy: 0.2096 - val_loss: 2.5598 - val_accuracy: 0.1447\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3753 - accuracy: 0.1965 - val_loss: 3.0613 - val_accuracy: 0.0526\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3520 - accuracy: 0.1878 - val_loss: 3.0391 - val_accuracy: 0.0526\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3196 - accuracy: 0.2271 - val_loss: 3.0638 - val_accuracy: 0.0395\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.3110 - accuracy: 0.2052 - val_loss: 2.6525 - val_accuracy: 0.1579\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3019 - accuracy: 0.2402 - val_loss: 3.0534 - val_accuracy: 0.0526\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2711 - accuracy: 0.2183 - val_loss: 3.0423 - val_accuracy: 0.0789\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3022 - accuracy: 0.2052 - val_loss: 2.6277 - val_accuracy: 0.1316\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2563 - accuracy: 0.2271 - val_loss: 2.7528 - val_accuracy: 0.1447\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2425 - accuracy: 0.2358 - val_loss: 2.7269 - val_accuracy: 0.1447\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.2259 - accuracy: 0.2576 - val_loss: 3.5026 - val_accuracy: 0.0789\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3056 - accuracy: 0.2140 - val_loss: 2.7189 - val_accuracy: 0.1579\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.1768 - accuracy: 0.2489 - val_loss: 3.0438 - val_accuracy: 0.1184\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.1925 - accuracy: 0.2402 - val_loss: 2.7969 - val_accuracy: 0.1447\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2182 - accuracy: 0.2358 - val_loss: 2.6793 - val_accuracy: 0.1316\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.1772 - accuracy: 0.2314 - val_loss: 2.7267 - val_accuracy: 0.1316\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.1507 - accuracy: 0.2533 - val_loss: 2.6186 - val_accuracy: 0.2368\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.1893 - accuracy: 0.2489 - val_loss: 2.5733 - val_accuracy: 0.1579\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 2.1190 - accuracy: 0.2707 - val_loss: 2.7695 - val_accuracy: 0.0658\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 2.1232 - accuracy: 0.2576 - val_loss: 2.5757 - val_accuracy: 0.2237\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.2681 - accuracy: 0.2358 - val_loss: 2.6513 - val_accuracy: 0.2368\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.1910 - accuracy: 0.2533 - val_loss: 2.5918 - val_accuracy: 0.1711\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.0748 - accuracy: 0.2838 - val_loss: 2.5640 - val_accuracy: 0.2237\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 2.0614 - accuracy: 0.2751 - val_loss: 2.5788 - val_accuracy: 0.2237\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.0444 - accuracy: 0.2707 - val_loss: 2.4913 - val_accuracy: 0.1974\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.9966 - accuracy: 0.2969 - val_loss: 2.4718 - val_accuracy: 0.2368\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.0053 - accuracy: 0.2838 - val_loss: 2.5553 - val_accuracy: 0.2105\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1.9690 - accuracy: 0.2838 - val_loss: 2.4487 - val_accuracy: 0.2237\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.9733 - accuracy: 0.2926 - val_loss: 2.5280 - val_accuracy: 0.1842\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.9521 - accuracy: 0.3144 - val_loss: 2.4947 - val_accuracy: 0.1842\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.8154 - accuracy: 0.3275 - val_loss: 2.4610 - val_accuracy: 0.2368\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.0700 - accuracy: 0.2664 - val_loss: 2.5289 - val_accuracy: 0.2237\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1.9795 - accuracy: 0.2926 - val_loss: 2.7075 - val_accuracy: 0.2368\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.0484 - accuracy: 0.2620 - val_loss: 2.7365 - val_accuracy: 0.1316\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x156472670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 20:03:16,918 : WARNING : 6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x156472670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([35, 35, 35, 35, 35, 35, 35,  8, 35, 35, 35, 35, 35, 35, 35, 38, 35,\n",
      "       35, 35, 38, 38, 35, 35, 38, 35, 38, 38, 35, 35, 32, 35, 35])\n",
      "array([35, 38, 35, 38, 35, 35, 35, 35, 35, 35, 35, 35, 35, 38, 35, 35, 38,\n",
      "       35, 35, 38, 35, 35, 38, 35, 38, 38, 35, 35, 38, 35, 35, 35])\n",
      "array([35, 35, 35, 38, 38, 38, 35, 35, 38, 35, 37, 38])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy():\n",
    "    def build_dataset_sce(chorales):\n",
    "        min_len = len(min(chorales, key=len))\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def trunc(chorale):\n",
    "            return chorale[:min_len+1]\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        dataset = dataset.map(trunc)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_sce(train_np_list)\n",
    "    val_dataset = build_dataset_sce(val_np_list)\n",
    "    test_dataset = build_dataset_sce(test_np_list)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.SimpleRNN(20),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=args.epochs, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396558e-c103-4e3b-807d-25fb66b6a711",
   "metadata": {},
   "source": [
    "### Sparse categorical entropy. Larger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "29f05bc8-146f-4954-9993-e9bff3aa421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 47])\n",
      "Epoch 1/3\n",
      "425/425 [==============================] - 5s 8ms/step - loss: 2.7636 - accuracy: 0.1698 - val_loss: 2.4375 - val_accuracy: 0.2174\n",
      "Epoch 2/3\n",
      "425/425 [==============================] - 3s 8ms/step - loss: 2.4126 - accuracy: 0.2220 - val_loss: 2.2203 - val_accuracy: 0.3199\n",
      "Epoch 3/3\n",
      "425/425 [==============================] - 3s 8ms/step - loss: 2.1993 - accuracy: 0.2931 - val_loss: 1.9243 - val_accuracy: 0.3696\n",
      "array([16, 16, 14, 16, 16,  9, 12, 12, 16, 16, 16, 16, 12, 14, 16, 16,  9,\n",
      "        9,  9, 16, 16, 12, 16, 16, 16, 12,  9, 14,  9,  9,  9, 12])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy_larger_dataset():\n",
    "    def build_dataset_sceld(chorales):\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def win(chorale):\n",
    "            window_size = 32\n",
    "            window_shift = 16\n",
    "            ds = tf.data.Dataset.from_tensor_slices(chorale).window(window_size, shift=window_shift, drop_remainder=True)\n",
    "            # flatten windows created by window() function\n",
    "            ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "            return ds\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        # flatten dataset created in win()\n",
    "        dataset = dataset.flat_map(win)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_sceld(train_np_list)\n",
    "    val_dataset = build_dataset_sceld(val_np_list)\n",
    "    test_dataset = build_dataset_sceld(test_np_list)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        keras.layers.SimpleRNN(20),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    # Shallow model doesn't need much training\n",
    "    model.fit(train_dataset, epochs=3, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        break\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy_larger_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dff2ad-0bce-4f3f-a269-55fa5ce52943",
   "metadata": {},
   "source": [
    "### Sparse categorical entropy. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee96a5d6-41cb-4861-a09d-18b3bc1add94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 47])\n",
      "Epoch 1/7\n",
      "425/425 [==============================] - 9s 15ms/step - loss: 1.9485 - accuracy: 0.3809 - val_loss: 1.3181 - val_accuracy: 0.4940\n",
      "Epoch 2/7\n",
      "425/425 [==============================] - 6s 13ms/step - loss: 1.0256 - accuracy: 0.6529 - val_loss: 0.7154 - val_accuracy: 0.7826\n",
      "Epoch 3/7\n",
      "425/425 [==============================] - 6s 14ms/step - loss: 0.7096 - accuracy: 0.7765 - val_loss: 0.6507 - val_accuracy: 0.7578\n",
      "Epoch 4/7\n",
      "425/425 [==============================] - 6s 14ms/step - loss: 0.5825 - accuracy: 0.8142 - val_loss: 0.3752 - val_accuracy: 0.9107\n",
      "Epoch 5/7\n",
      "425/425 [==============================] - 6s 13ms/step - loss: 0.4877 - accuracy: 0.8498 - val_loss: 0.5630 - val_accuracy: 0.7459\n",
      "Epoch 6/7\n",
      "425/425 [==============================] - 6s 13ms/step - loss: 0.3989 - accuracy: 0.8786 - val_loss: 0.3935 - val_accuracy: 0.8875\n",
      "Epoch 7/7\n",
      "425/425 [==============================] - 6s 14ms/step - loss: 0.4187 - accuracy: 0.8786 - val_loss: 0.7115 - val_accuracy: 0.7793\n",
      "array([16, 17, 14, 17, 19,  7, 12, 12, 20, 17, 20, 21, 14, 15, 16, 16,  9,\n",
      "        9,  9, 19, 16, 14, 21, 18, 18, 14, 10, 14,  7,  7,  7, 12])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy_lstm():\n",
    "    def build_dataset_scelstm(chorales):\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def win(chorale):\n",
    "            window_size = 32\n",
    "            window_shift = 16\n",
    "            ds = tf.data.Dataset.from_tensor_slices(chorale).window(window_size, shift=window_shift, drop_remainder=True)\n",
    "            # flatten windows created by window() function\n",
    "            ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "            return ds\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        # flatten dataset created in win()\n",
    "        dataset = dataset.flat_map(win)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_scelstm(train_np_list)\n",
    "    val_dataset = build_dataset_scelstm(val_np_list)\n",
    "    test_dataset = build_dataset_scelstm(test_np_list)\n",
    "    \n",
    "    n_embedding_dims = 5\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(20, return_sequences=True, input_shape=(None, 1)),\n",
    "        keras.layers.LSTM(20, return_sequences=False),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=7, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        break\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy_lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbdd0c-482b-43ed-8170-7557c34aa442",
   "metadata": {},
   "source": [
    "### Sparse categorical entropy. Deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f226aee3-0067-443e-8c0f-2d2f0e0f0ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 47])\n",
      "Epoch 1/7\n",
      "425/425 [==============================] - 7s 10ms/step - loss: 2.1575 - accuracy: 0.2740 - val_loss: 1.9878 - val_accuracy: 0.2388\n",
      "Epoch 2/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 1.4584 - accuracy: 0.4495 - val_loss: 1.6862 - val_accuracy: 0.2881\n",
      "Epoch 3/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 1.1594 - accuracy: 0.5613 - val_loss: 1.2188 - val_accuracy: 0.4609\n",
      "Epoch 4/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 0.9752 - accuracy: 0.6397 - val_loss: 1.2244 - val_accuracy: 0.6021\n",
      "Epoch 5/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 0.8162 - accuracy: 0.6990 - val_loss: 0.8435 - val_accuracy: 0.6706\n",
      "Epoch 6/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 0.6896 - accuracy: 0.7587 - val_loss: 0.6219 - val_accuracy: 0.7459\n",
      "Epoch 7/7\n",
      "425/425 [==============================] - 4s 9ms/step - loss: 0.5843 - accuracy: 0.7973 - val_loss: 0.7253 - val_accuracy: 0.7095\n",
      "array([16, 17, 14, 16, 19,  6, 12, 12, 19, 16, 19, 21, 14, 14, 16, 16,  9,\n",
      "        8,  8, 19, 16, 14, 21, 18, 17, 14,  9, 14,  7,  7,  7, 12])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy_deep_network1():\n",
    "    def build_dataset_scedn1(chorales):\n",
    "        min_len = len(min(chorales, key=len))\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def win(chorale):\n",
    "            window_size = 32\n",
    "            window_shift = 16\n",
    "            ds = tf.data.Dataset.from_tensor_slices(chorale).window(window_size, shift=window_shift, drop_remainder=True)\n",
    "            # flatten windows created by window() function\n",
    "            ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "            return ds\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        # flatten dataset created in win()\n",
    "        dataset = dataset.flat_map(win)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_scedn1(train_np_list)\n",
    "    val_dataset = build_dataset_scedn1(val_np_list)\n",
    "    test_dataset = build_dataset_scedn1(test_np_list)\n",
    "    \n",
    "    n_embedding_dims = 5\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(None, 1)),\n",
    "        keras.layers.Conv1D(20, kernel_size=4, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "        keras.layers.GRU(20, return_sequences=True),\n",
    "        keras.layers.GRU(20, return_sequences=False),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=7, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        break\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy_deep_network1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a26aa9b0-351e-4dc5-ac8b-1a536e1a1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 47])\n",
      "Epoch 1/7\n",
      "425/425 [==============================] - 18s 36ms/step - loss: 0.3689 - accuracy: 0.9054 - val_loss: 0.2655 - val_accuracy: 0.9286\n",
      "Epoch 2/7\n",
      "425/425 [==============================] - 14s 33ms/step - loss: 0.0974 - accuracy: 0.9786 - val_loss: 0.0780 - val_accuracy: 0.9834\n",
      "Epoch 3/7\n",
      "425/425 [==============================] - 14s 33ms/step - loss: 0.0724 - accuracy: 0.9845 - val_loss: 0.4084 - val_accuracy: 0.9289\n",
      "Epoch 4/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.0709 - accuracy: 0.9862 - val_loss: 0.2900 - val_accuracy: 0.9227\n",
      "Epoch 5/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.1025 - accuracy: 0.9758 - val_loss: 0.0527 - val_accuracy: 0.9909\n",
      "Epoch 6/7\n",
      "425/425 [==============================] - 15s 34ms/step - loss: 0.0535 - accuracy: 0.9899 - val_loss: 0.0494 - val_accuracy: 0.9912\n",
      "Epoch 7/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.0653 - accuracy: 0.9862 - val_loss: 0.0744 - val_accuracy: 0.9817\n",
      "array([16, 17, 14, 17, 19,  7, 12, 12, 19, 16, 20, 21, 14, 14, 16, 16,  9,\n",
      "        9,  9, 19, 16, 14, 21, 18, 18, 14,  9, 14,  7,  7,  7, 12])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy_deep_network2():\n",
    "    def build_dataset_scedn2(chorales):\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def win(chorale):\n",
    "            window_size = 32\n",
    "            window_shift = 16\n",
    "            ds = tf.data.Dataset.from_tensor_slices(chorale).window(window_size, shift=window_shift, drop_remainder=True)\n",
    "            # flatten windows created by window() function\n",
    "            ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "            return ds\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[-1]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        # flatten dataset created in win()\n",
    "        dataset = dataset.flat_map(win)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_scedn2(train_np_list)\n",
    "    val_dataset = build_dataset_scedn2(val_np_list)\n",
    "    test_dataset = build_dataset_scedn2(test_np_list)\n",
    "    \n",
    "    n_embedding_dims = 5\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(input_dim=num_notes, output_dim=n_embedding_dims,\n",
    "                               input_shape=[None]),\n",
    "        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LSTM(256, return_sequences=False),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=7, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        break\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy_deep_network2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93d931-255b-4c0f-a9d1-bbc8a0a01f68",
   "metadata": {},
   "source": [
    "### Sparse categorical entropy. Deep network. Predicting sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1f5b093-18e4-4ee5-8604-873abd09b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 31, 47])\n",
      "Epoch 1/7\n",
      "425/425 [==============================] - 18s 35ms/step - loss: 0.9438 - accuracy: 0.7441 - val_loss: 0.8756 - val_accuracy: 0.7515\n",
      "Epoch 2/7\n",
      "425/425 [==============================] - 15s 36ms/step - loss: 0.6085 - accuracy: 0.8194 - val_loss: 0.7039 - val_accuracy: 0.7940\n",
      "Epoch 3/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.5617 - accuracy: 0.8312 - val_loss: 0.6748 - val_accuracy: 0.8011\n",
      "Epoch 4/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.5372 - accuracy: 0.8371 - val_loss: 0.6493 - val_accuracy: 0.8070\n",
      "Epoch 5/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.5229 - accuracy: 0.8403 - val_loss: 0.6432 - val_accuracy: 0.8089\n",
      "Epoch 6/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.5163 - accuracy: 0.8421 - val_loss: 0.6273 - val_accuracy: 0.8139\n",
      "Epoch 7/7\n",
      "425/425 [==============================] - 14s 34ms/step - loss: 0.5117 - accuracy: 0.8428 - val_loss: 0.6355 - val_accuracy: 0.8140\n",
      "array([[29, 14,  2, ..., 14,  2, 16],\n",
      "       [13, 13, 13, ..., 13, 13, 13],\n",
      "       [ 2,  1,  2, ...,  2,  2,  2],\n",
      "       ...,\n",
      "       [ 0,  2, 10, ..., 15, 10,  0],\n",
      "       [ 0,  2, 10, ..., 15, 10,  0],\n",
      "       [18, 18, 10, ..., 15, 10,  0]])\n"
     ]
    }
   ],
   "source": [
    "def sparse_categorical_entropy_deep_network2_seq():\n",
    "    def build_dataset_scedn2s(chorales):\n",
    "        def reshape(chorale):\n",
    "            chorale = tf.reshape(chorale.to_tensor(), [-1, 1])\n",
    "            return chorale\n",
    "        def win(chorale):\n",
    "            window_size = 32\n",
    "            window_shift = 16\n",
    "            ds = tf.data.Dataset.from_tensor_slices(chorale).window(window_size, shift=window_shift, drop_remainder=True)\n",
    "            # flatten windows created by window() function\n",
    "            ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "            return ds\n",
    "        def transform(chorale):\n",
    "            return tf.where(chorale == 0, 0, chorale - min_note)\n",
    "        def target(chorale):\n",
    "            X = chorale[:-1]\n",
    "            Y = chorale[1:]\n",
    "            return X, Y\n",
    "\n",
    "        ragged_chorales = tf.ragged.constant(chorales)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ragged_chorales)\n",
    "        dataset = dataset.map(reshape)\n",
    "        # flatten dataset created in win()\n",
    "        dataset = dataset.flat_map(win)\n",
    "        dataset = dataset.map(transform)\n",
    "        dataset = dataset.map(target)\n",
    "        dataset = dataset.batch(32)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    train_dataset = build_dataset_scedn2s(train_np_list)\n",
    "    val_dataset = build_dataset_scedn2s(val_np_list)\n",
    "    test_dataset = build_dataset_scedn2s(test_np_list)\n",
    "    \n",
    "    n_embedding_dims = 5\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(input_dim=num_notes, output_dim=n_embedding_dims,\n",
    "                               input_shape=[None]),\n",
    "        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LSTM(256, return_sequences=True),\n",
    "        keras.layers.Dense(num_notes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    for d in train_dataset:\n",
    "        tf.print(model(d[0]).shape)\n",
    "        break\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=keras.optimizers.Nadam(learning_rate=0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=7, validation_data=val_dataset)\n",
    "    \n",
    "    for d in val_dataset:\n",
    "        tf.print(np.argmax(model.predict(d[0]), axis=1))\n",
    "        break\n",
    "        \n",
    "    \n",
    "sparse_categorical_entropy_deep_network2_seq()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
