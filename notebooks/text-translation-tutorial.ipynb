{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be0f2f1-7f61-4d19-a9f7-6e27ac9c0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "use_builtins = True\n",
    "\n",
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # Keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "      \n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f'Rank mismatch:\\n'\n",
    "                           f'    found {rank}: {shape.numpy()}\\n'\n",
    "                           f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                             f\"    found: {new_dim}\\n\"\n",
    "                             f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c35f5-ed78-4e95-9fd3-cd692deea894",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7067c97-ed48-4194-9609-b164788b1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 1s 0us/step\n",
      "2654208/2638744 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True,\n",
    "    cache_dir='data-ignored/translation')\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a98e3a-104c-46a8-a580-299344a08297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
      "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
     ]
    }
   ],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "\n",
    "    return targ, inp\n",
    "\n",
    "targ, inp = load_data(path_to_file)\n",
    "print(inp[-1])\n",
    "print(targ[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdea91a-b857-48fc-bb5b-b3c6906f0ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 14:52:02.478638: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Todos pueden cometer errores.'], shape=(1,), dtype=string)\n",
      "\n",
      "tf.Tensor([b'Anyone can make mistakes.'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    print(example_input_batch[:1])\n",
    "    print()\n",
    "    print(example_target_batch[:1])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d113f4-6a1d-4554-adc1-baabb63732ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n",
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n",
      "tf.Tensor(\n",
      "[[   2   66  414 1635  672    4    3    0    0    0]\n",
      " [   2   89    9 1384   35  279    4    3    0    0]\n",
      " [   2    9   48  108    4    3    0    0    0    0]], shape=(3, 10), dtype=int64)\n",
      "['[START]' 'todos' 'pueden' 'cometer' 'errores' '.' '[END]' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '']\n"
     ]
    }
   ],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accecented characters.\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text\n",
    "\n",
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "\n",
    "input_text_processor.adapt(inp)\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "print(input_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "output_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "\n",
    "output_text_processor.adapt(targ)\n",
    "print(output_text_processor.get_vocabulary()[:10])\n",
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "\n",
    "\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "print(example_tokens[:3, :10])\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d57630-12c8-4fdd-91bc-f3f5f8bb4eaa",
   "metadata": {},
   "source": [
    "### Encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2bc57a-58a6-409b-9a14-66c93b75e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 22)\n",
      "Encoder output, shape (batch, s, units): (64, 22, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       # Return the sequence and state\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, ('batch', 's'))\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "\n",
    "        # 3. The GRU processes the embedding sequence.\n",
    "        #    output shape: (batch, s, enc_units)\n",
    "        #    state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "        shape_checker(state, ('batch', 'enc_units'))\n",
    "\n",
    "        # 4. Returns the new sequence and its state.\n",
    "        return output, state\n",
    "\n",
    "# Convert the input text to tokens.\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "\n",
    "# Encode the input sequence.\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "\n",
    "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ece3939-07cc-4ecc-9fdc-7bdcb56b49a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 22)\n",
      "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 22)\n"
     ]
    }
   ],
   "source": [
    "# Attention\n",
    "# dec -> query\n",
    "# enc -> value\n",
    "# value_units ~ enc units or units\n",
    "# query_units ~ dec units\n",
    "# s -> enc input sequence\n",
    "# t -> dec input sequence\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        # For Eqn. (4), the  Bahdanau attention\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "    \n",
    "    def call(self, query, value, mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "\n",
    "        # From Eqn. (4), `W1@ht`.\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "\n",
    "        # From Eqn. (4), `W2@hs`.\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs = [w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores = True,\n",
    "        )\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_layer = BahdanauAttention(units)\n",
    "print((example_tokens != 0).shape)\n",
    "\n",
    "# Later, the decoder will generate this attention query\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=example_enc_output,\n",
    "    mask=(example_tokens != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length (t), units (attention units)):           {context_vector.shape}')\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length (t), value_seq_length (s)): {attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161014c6-ca9e-45d0-92c7-d6e7e1aa80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (batch_size, t, output_vocab_size) (64, 1, 5000)\n",
      "state shape: (batch_size, dec_units) (64, 1024)\n",
      "[['pistol']\n",
      " ['gonna']\n",
      " ['coming']\n",
      " ['bench']\n",
      " ['every']]\n",
      "[['europe']\n",
      " ['pockets']\n",
      " ['stabbed']\n",
      " ['collection']\n",
      " ['mustnt']]\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # For Step 1. The embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        # For step 3. The RNN output will be the query for the attention layer.\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "\n",
    "        # For step 5. This fully connected layer produces the logits for each\n",
    "        # output token.\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
    "        \n",
    "    def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "            shape_checker = ShapeChecker()\n",
    "            shape_checker(inputs.new_tokens, ('batch', 't'))\n",
    "            shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
    "            shape_checker(inputs.mask, ('batch', 's'))\n",
    "\n",
    "            if state is not None:\n",
    "                shape_checker(state, ('batch', 'dec_units'))\n",
    "\n",
    "            # Step 1. Lookup the embeddings\n",
    "            vectors = self.embedding(inputs.new_tokens)\n",
    "            shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
    "\n",
    "            # Step 2. Process one step with the RNN\n",
    "            rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "\n",
    "            shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
    "            shape_checker(state, ('batch', 'dec_units'))\n",
    "\n",
    "            # Step 3. Use the RNN output as the query for the attention over the\n",
    "            # encoder output.\n",
    "            context_vector, attention_weights = self.attention(\n",
    "              query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "            shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
    "            shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "\n",
    "            # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
    "            #     [ct; ht] shape: (batch t, value_units + query_units)\n",
    "            context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "\n",
    "            # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
    "            attention_vector = self.Wc(context_and_rnn_output)\n",
    "            shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
    "\n",
    "            # Step 5. Generate logit predictions:\n",
    "            logits = self.fc(attention_vector)\n",
    "            shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
    "\n",
    "            return DecoderOutput(logits, attention_weights), state\n",
    "\n",
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "\n",
    "# Usage example\n",
    "# Convert the target sequence, and collect the \"[START]\" tokens\n",
    "example_output_tokens = output_text_processor(example_target_batch)\n",
    "\n",
    "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
    "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])\n",
    "\n",
    "# Run the decoder\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs = DecoderInput(new_tokens=first_token,\n",
    "                          enc_output=example_enc_output,\n",
    "                          mask=(example_tokens != 0)),\n",
    "    state = example_enc_state\n",
    ")\n",
    "\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n",
    "\n",
    "# Sample a token according to the logits and decode the token as the first word of the output. First prediction\n",
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "vocab = np.array(output_text_processor.get_vocabulary())\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])\n",
    "\n",
    "# Second prediction\n",
    "dec_result, dec_state = decoder(\n",
    "    DecoderInput(sampled_token,\n",
    "                 example_enc_output,\n",
    "                 mask=(example_tokens != 0)),\n",
    "    state=dec_state)\n",
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e051c6-db9a-4c43-8462-b2c9d90c14b8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6347fbca-2195-4b02-8f34-41edf2f7f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6058345>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5738454>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5131044>}\n",
      "0:00:09.292453\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(y_true, ('batch', 't'))\n",
    "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
    "\n",
    "        # Calculate the loss for each item in the batch.\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        shape_checker(loss, ('batch', 't'))\n",
    "\n",
    "        # Mask off the losses on padding.\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "        shape_checker(mask, ('batch', 't'))\n",
    "        loss *= mask\n",
    "\n",
    "        # Return the total.\n",
    "        return tf.reduce_sum(loss)\n",
    "    \n",
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "               input_text_processor,\n",
    "               output_text_processor, \n",
    "               use_tf_function=True):\n",
    "        super().__init__()\n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)\n",
    "    \n",
    "    def _preprocess(self, input_text, target_text):\n",
    "        self.shape_checker(input_text, ('batch',))\n",
    "        self.shape_checker(target_text, ('batch',))\n",
    "\n",
    "        # Convert the text to token IDs\n",
    "        input_tokens = self.input_text_processor(input_text)\n",
    "        target_tokens = self.output_text_processor(target_text)\n",
    "        self.shape_checker(input_tokens, ('batch', 's'))\n",
    "        self.shape_checker(target_tokens, ('batch', 't'))\n",
    "\n",
    "        # Convert IDs to masks.\n",
    "        input_mask = input_tokens != 0\n",
    "        self.shape_checker(input_mask, ('batch', 's'))\n",
    "\n",
    "        target_mask = target_tokens != 0\n",
    "        self.shape_checker(target_mask, ('batch', 't'))\n",
    "\n",
    "        return input_tokens, input_mask, target_tokens, target_mask\n",
    "    \n",
    "    def _train_step(self, inputs):\n",
    "        input_text, target_text = inputs  \n",
    "\n",
    "        (input_tokens, input_mask,\n",
    "        target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "\n",
    "        max_target_length = tf.shape(target_tokens)[1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Encode the input\n",
    "            enc_output, enc_state = self.encoder(input_tokens)\n",
    "            self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "            self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "\n",
    "            # Initialize the decoder's state to the encoder's final state.\n",
    "            # This only works if the encoder and decoder have the same number of\n",
    "            # units.\n",
    "            dec_state = enc_state\n",
    "            loss = tf.constant(0.0)\n",
    "\n",
    "            for t in tf.range(max_target_length-1):\n",
    "              # Pass in two tokens from the target sequence:\n",
    "              # 1. The current input to the decoder.\n",
    "              # 2. The target for the decoder's next prediction.\n",
    "                new_tokens = target_tokens[:, t:t+2]\n",
    "                step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                         enc_output, dec_state)\n",
    "                loss = loss + step_loss\n",
    "\n",
    "            # Average the loss over all non padding tokens.\n",
    "            average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "\n",
    "        # Apply an optimization step\n",
    "        variables = self.trainable_variables \n",
    "        gradients = tape.gradient(average_loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {'batch_loss': average_loss}\n",
    "    \n",
    "    def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "        input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "\n",
    "        # Run the decoder one step.\n",
    "        decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                                   enc_output=enc_output,\n",
    "                                   mask=input_mask)\n",
    "\n",
    "        dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "        self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
    "        self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
    "        self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
    "\n",
    "        # `self.loss` returns the total for non-padded tokens\n",
    "        y = target_token\n",
    "        y_pred = dec_result.logits\n",
    "        step_loss = self.loss(y, y_pred)\n",
    "\n",
    "        return step_loss, dec_state \n",
    "    \n",
    "    # tf function is faster\n",
    "    @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "    def _tf_train_step(self, inputs):\n",
    "        return self._train_step(inputs)\n",
    "    \n",
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "for n in range(3):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print(datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8680e6c0-88e9-416d-a19c-d7b40641df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9765253>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9597201>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.989764>}\n",
      "0:00:05.184365\n"
     ]
    }
   ],
   "source": [
    "translator.use_tf_function = True\n",
    "start_time = datetime.datetime.now()\n",
    "for n in range(3):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print(datetime.datetime.now() - start_time)\n",
    "\n",
    "# reset model\n",
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7afcd8-a188-44a6-93e2-efa9deca7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1859/1859 [==============================] - 2381s 1s/step - batch_loss: 2.0793\n",
      "Epoch 2/3\n",
      "1859/1859 [==============================] - 2583s 1s/step - batch_loss: 1.0463\n",
      "Epoch 3/3\n",
      "1859/1859 [==============================] - 2349s 1s/step - batch_loss: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158e7edc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')\n",
    "\n",
    "train_translator.fit(dataset, epochs=3,\n",
    "                     callbacks=[batch_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f108a9-9314-4c78-acad-159635e308ad",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddbfd582-528c-4fee-974a-a387adc28ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6qklj4h53bv0c1rjnffg7bmw0000gp/T/ipykernel_80609/3155067552.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its very cold here .\n",
      "this is my life .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Translator(tf.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, input_text_processor,\n",
    "               output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "\n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=output_text_processor.get_vocabulary(),\n",
    "                mask_token='',\n",
    "                invert=True))\n",
    "\n",
    "        # The output should never generate padding, unknown, or start.\n",
    "        index_from_string = tf.keras.layers.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "\n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "\n",
    "        self.start_token = index_from_string(tf.constant('[START]'))\n",
    "        self.end_token = index_from_string(tf.constant('[END]'))\n",
    "        \n",
    "    def tokens_to_text(self, result_tokens):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(result_tokens, ('batch', 't'))\n",
    "        result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "        shape_checker(result_text_tokens, ('batch', 't'))\n",
    "\n",
    "        result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                           axis=1, separator=' ')\n",
    "        shape_checker(result_text, ('batch'))\n",
    "\n",
    "        result_text = tf.strings.strip(result_text)\n",
    "        shape_checker(result_text, ('batch',))\n",
    "        return result_text\n",
    "    \n",
    "    def sample(self, logits, temperature):\n",
    "        shape_checker = ShapeChecker()\n",
    "        # 't' is usually 1 here.\n",
    "        shape_checker(logits, ('batch', 't', 'vocab'))\n",
    "        shape_checker(self.token_mask, ('vocab',))\n",
    "\n",
    "        token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "        shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
    "\n",
    "        # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
    "        logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "\n",
    "        if temperature == 0.0:\n",
    "            new_tokens = tf.argmax(logits, axis=-1)\n",
    "        else: \n",
    "            logits = tf.squeeze(logits, axis=1)\n",
    "            new_tokens = tf.random.categorical(logits/temperature,\n",
    "                                            num_samples=1)\n",
    "\n",
    "        shape_checker(new_tokens, ('batch', 't'))\n",
    "        return new_tokens\n",
    "    \n",
    "    def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "        batch_size = tf.shape(input_text)[0]\n",
    "        input_tokens = self.input_text_processor(input_text)\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "\n",
    "        dec_state = enc_state\n",
    "        new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "\n",
    "        result_tokens = []\n",
    "        attention = []\n",
    "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                                     enc_output=enc_output,\n",
    "                                     mask=(input_tokens!=0))\n",
    "\n",
    "            dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "\n",
    "            attention.append(dec_result.attention_weights)\n",
    "\n",
    "            new_tokens = self.sample(dec_result.logits, temperature)\n",
    "\n",
    "            # If a sequence produces an `end_token`, set it `done`\n",
    "            done = done | (new_tokens == self.end_token)\n",
    "            # Once a sequence is done it only produces 0-padding.\n",
    "            new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "\n",
    "            # Collect the generated tokens\n",
    "            result_tokens.append(new_tokens)\n",
    "\n",
    "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "                break\n",
    "\n",
    "        # Convert the list of generates token ids to a list of strings.\n",
    "        result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "        result_text = self.tokens_to_text(result_tokens)\n",
    "\n",
    "        if return_attention:\n",
    "            attention_stack = tf.concat(attention, axis=1)\n",
    "            return {'text': result_text, 'attention': attention_stack}\n",
    "        else:\n",
    "            return {'text': result_text}\n",
    "\n",
    "        \n",
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")\n",
    "\n",
    "input_text = tf.constant([\n",
    "    'hace mucho frio aqui.', # \"It's really cold here.\"\n",
    "    'Esta es mi vida.', # \"This is my life.\"\"\n",
    "])\n",
    "\n",
    "result = translator.translate_unrolled(\n",
    "    input_text = input_text)\n",
    "\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf4af55-76ca-437e-ba3a-3d4ca1ca3234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000001  0.99999994 1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_attention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g9/6qklj4h53bv0c1rjnffg7bmw0000gp/T/ipykernel_80609/2539027612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_attention' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = result['attention'][0]\n",
    "\n",
    "print(np.sum(a, axis=-1))\n",
    "_ = plt.bar(range(len(a[0, :])), a[0, :])\n",
    "\n",
    "\n",
    "i=0\n",
    "plot_attention(result['attention'][i], input_text[i], result['text'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
