{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838093c3-cb8a-4a10-aa5e-b3fb28d7617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:34:15,026 : INFO : No config specified, defaulting to first: imdb_reviews/plain_text\n",
      "2021-10-23 14:34:15,027 : INFO : Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: imdb_reviews/plain_text/1.0.0\n",
      "2021-10-23 14:34:15,520 : INFO : Load dataset info from /var/folders/g9/6qklj4h53bv0c1rjnffg7bmw0000gp/T/tmpdf1rb4cdtfds\n",
      "2021-10-23 14:34:15,523 : INFO : Field info.config_name from disk and from code do not match. Keeping the one from code.\n",
      "2021-10-23 14:34:15,523 : INFO : Field info.config_description from disk and from code do not match. Keeping the one from code.\n",
      "2021-10-23 14:34:15,523 : INFO : Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "2021-10-23 14:34:15,524 : INFO : Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "2021-10-23 14:34:15,524 : INFO : Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "2021-10-23 14:34:15,525 : INFO : Generating dataset imdb_reviews (./data-ignored/imdb/imdb_reviews/plain_text/1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ./data-ignored/imdb/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31afa58d7554c90a298c0015c63bcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bd21eb08c04f61b51e888b107b4483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:34:16,030 : INFO : Downloading http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz into data-ignored/imdb/downloads/ai.stanfor.edu_amaas_sentime_aclImdb_v1PaujRp-TxjBWz59jHXsMDm5WiexbxzaFQkEnXc3Tvo8.tar.gz.tmp.4f8b81bdc21b4ba499eb4e7c2bda5cdb...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:36:26,278 : INFO : Done writing imdb_reviews-train.tfrecord. Number of examples: 25000 (shards: [25000])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:36:37,378 : INFO : Done writing imdb_reviews-test.tfrecord. Number of examples: 25000 (shards: [25000])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:36:52,708 : INFO : Done writing imdb_reviews-unsupervised.tfrecord. Number of examples: 50000 (shards: [50000])\n",
      "2021-10-23 14:36:52,712 : INFO : Constructing tf.data.Dataset imdb_reviews for split None, from ./data-ignored/imdb/imdb_reviews/plain_text/1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to ./data-ignored/imdb/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 14:36:52.735467: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({Split('train'): <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       "  Split('test'): <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       "  Split('unsupervised'): <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>},\n",
       " tfds.core.DatasetInfo(\n",
       "     name='imdb_reviews',\n",
       "     full_name='imdb_reviews/plain_text/1.0.0',\n",
       "     description=\"\"\"\n",
       "     Large Movie Review Dataset.\n",
       "     This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
       "     \"\"\",\n",
       "     config_description=\"\"\"\n",
       "     Plain text\n",
       "     \"\"\",\n",
       "     homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "     data_path='./data-ignored/imdb/imdb_reviews/plain_text/1.0.0',\n",
       "     download_size=80.23 MiB,\n",
       "     dataset_size=129.83 MiB,\n",
       "     features=FeaturesDict({\n",
       "         'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "         'text': Text(shape=(), dtype=tf.string),\n",
       "     }),\n",
       "     supervised_keys=('text', 'label'),\n",
       "     disable_shuffling=False,\n",
       "     splits={\n",
       "         'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
       "         'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
       "         'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "     },\n",
       "     citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "       author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "       title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "       booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "       month     = {June},\n",
       "       year      = {2011},\n",
       "       address   = {Portland, Oregon, USA},\n",
       "       publisher = {Association for Computational Linguistics},\n",
       "       pages     = {142--150},\n",
       "       url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "     }\"\"\",\n",
       " ))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import argparse \n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.data_folder = './data-ignored/imdb/'\n",
    "\n",
    "\n",
    "Path(args.data_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ds = tfds.load('imdb_reviews', with_info=True, as_supervised=True, data_dir=args.data_folder)\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
